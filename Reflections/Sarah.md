# Sarah AI Puzzler Reflections

This process was so interesting! At the outset, I was unsure of how to implmenent AI into my workflow in a way that would produce the kind of data that Olio seemed to be looking for. Once we got started, I realized it would be interesting to just let it completely takeover. We started by feeding it all the information for the project and asking it to write a tech design. This was all done in ChatGPT. I would say that this was a very helpful jumping off point. When we were given the prompt, being unfamiliar with Express and FileSystem, I had no idea where to start with. Had I not been using AI, I would have probably spent a whole day or afternoon googling, watching videos, and reading stack overflow threads on Express and FileSystem. By asking ChatGPT to create a tech design, I started to see where we would begin building. 

After having ChatGPT write the tech design, we had it write a series of tickets based off of the approach section that it had written in the tech design. It was almost like a step-by-step guide on where to begin and what to do. It seemed very helpful to begin with and saved us a lot of time writing those individual tickets. However, once we actually began coding, it became difficult to follow along with the flow of tickets that ChatGPT had created. We started straying from the GPT-prescribed path and began writing our own tickets as we saw fit. We still had ChatGPT write the actual ticket but we were deciding the steps at that point. We realized that the tckets that ChatGPT had created didn't end up being too helpful. This part of the process was interesting as it showed where the humans and the robots strayed. It would have been impossible or a waster of time to try and follow each of the tickets to a t.

Once we got into the thick of coding and then were given further instruction on how to design the architecture of the project, then the process sped up quite a bit. If I had been on my own after being instructed to create a provider layer, it would have taken me probably an entire day to figure that out. With co-pilot, it came together in an afternoon. I was able to create a UserProvider class with the necessary methods and then add those methods into the controller. I accomplished this in about 20 minutes. I tested each endpoint using cURL to make sure that everything had been hooked up correctly. All of those tests passed but I did not know how to write jest tests for this layer. Because things were coming together so fast, we just kept pushing forward. As we have discussed in several meetings, this part of the project effectively broke the traditional development workflow. Had we had followed the traditional flow of creating PRs for each set of new code and waiting for feedback, we would have had nothing else to do. Because of this, we did not receive any direct feedback for the actual building of the project and ended up with a fairly large codebase that was untested and largely unfamiliar to us. There is a lot of room for innovation here about what this process could do look like now with AI involved, but there definitely should be some stopgaps in place to avoid the scenario that we had where we ended up with all this code that we didn't know how to test or debug. 

Something I've been reflecting on in this process is the top down approach we ended up having to take. I used the analogy of building a car engine; if I were to set out to build a car engine, I might want to start with a fully built one and take it apart to see how all the pieces fir together. This is a style of learning that I quite enjoy and feel like it works well for me. I felt like this experience was in that vein as we ended up creating the whole car engine using co-pilot mainly and then ended up with a finished product that we needed to then pick apart and try to understand. 

Overall, I feel very proud of what we accomplished this week and I feel that I learned a lot. I know that this is a brand new module and we were effectively the guinea pigs but I very much liked how self-directed it was. I liked being given the project and then told basically "go forth and tell us what you learn". I felt a lot of freedom to do it my own way and to conduct a lot of trial and error. That is another style of learning that works really well for me. I think that for future interns, this module will need to include a structure of review so that the devs working on it can be receving feedback on their work. I'm not sure what I think that might look like because it's the velocity at which we were able to code that ended up being the problem in that regard. I think this might be a million dollar question when it comes to bringing AI in to the software development workspace. 